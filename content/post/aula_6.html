---
title: "Aula 6 - Distribuições Normal, chi-quadrado e F"
author: "Rafael Bassi Stern"
date: 2018-04-04
bibliography: ipaee.bib
output: html_document
---



<div id="propriedades-de-variaveis-aleatorias" class="section level1">
<h1>Propriedades de variáveis aleatórias</h1>
<p>Uma forma de descrever a incerteza em relação a uma variável aleatória é por meio de sua <strong>função de densidade</strong>. Se <span class="math inline">\(X\)</span> é uma variável aleatória, geralmente designamos a função de densidade de <span class="math inline">\(X\)</span> por <span class="math inline">\(f_{X}(x)\)</span>. O valor de <span class="math inline">\(f_{X}(x)\)</span> indica o quão plausível é que a variável aleatória <span class="math inline">\(X\)</span> assuma o valor <span class="math inline">\(x\)</span>. Por exemplo, a figura abaixo indica uma variável aleatória contínua tal que todos os valores entre 0 e 1 são igualmente plausíveis. Por isso, é comum dizer que esta variável aleatória tem densidade uniforme entre 0 e 1.</p>
<pre class="r"><code>library(tidyverse)
ggplot(data.frame(x = c(0, 1)), aes(x)) + 
stat_function(fun = dunif, colour = &quot;red&quot;, n = 100)</code></pre>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Uma propriedade importante de uma função de densidade é que podemos obter a probabilidade de que <span class="math inline">\(X\)</span> esteja entre dois valores, <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span>, calculando a área debaixo da densidade. Note que de corre desta propriedade que a área total debaixo da densidade é <span class="math inline">\(1\)</span>. Por exemplo, a figura abaixo ilustra como obter <span class="math inline">\(P(0.25 &lt; X &lt; 0.5)\)</span> quando <span class="math inline">\(X\)</span> tem densidade uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>. Note que, neste caso, a figura abaixo da curva é um retângulo de base <span class="math inline">\(0.25\)</span> e altura <span class="math inline">\(1\)</span> e, portanto, de área <span class="math inline">\(0.25\)</span>. Assim, obtemos que <span class="math inline">\(P(0.25 &lt; X &lt; 0.5) = 0.25\)</span>. Também, a área total debaixo da densidade é dada por um quadrado de lado <span class="math inline">\(1\)</span>, isto é, <span class="math inline">\(1\)</span>. Portanto, como esperávamos, <span class="math inline">\(P(0 &lt; X &lt; 1) = 1\)</span>.</p>
<pre class="r"><code>ggplot(data.frame(x = c(0, 1)), aes(x)) + 
stat_function(fun = dunif, colour = &quot;red&quot;, n = 100) +
stat_function(fun = dunif, xlim = c(0.25, 0.5), geom = &quot;area&quot;, alpha = 0.5) </code></pre>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>De forma geral, a área debaixo de uma curva é dada por uma integral. Neste curso não usaremos esta relação, mas é útil saber que, se <span class="math inline">\(X\)</span> é uma variável contínua, então obtemos que <span class="math display">\[P(x_1 \leq X \leq x_2) = \int_{x_1}^{x_2} f_{X}(x)dx\]</span></p>
<p>Também note que a área entre <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span> pode ser descrita como a área à esquerda de <span class="math inline">\(x_2\)</span> subtraída da área à esquerda de <span class="math inline">\(x_1\)</span>. Assim, se <span class="math inline">\(X\)</span> é uma variável contínua, também vale a seguinte relação <span class="math display">\[P(x_1 \leq X \leq x_2) = P(X \leq x_2) - P(X \leq x_1)\]</span></p>
<p>A função de densidade descreve toda a incerteza sobre uma variável aleatória. Contudo, pode ser difícil descrever e analisar uma função. Assim, é comum que certos aspectos de uma variável aleatória sejam resumidos em números. A seguir, estudamos algumas destas medidas resumo.</p>
<ul>
<li><p><strong>Esperança</strong> (média populacional): A esperança de uma varíavel aleatória, <span class="math inline">\(X\)</span> é denotada por <span class="math inline">\(E[X]\)</span> e descreve uma medida de centralidade desta. Se imaginarmos que, para cada possível valor, <span class="math inline">\(x\)</span>, existe um peso de <span class="math inline">\(f_{X}(x)\)</span> na posição <span class="math inline">\(x\)</span>, então <span class="math inline">\(E[X]\)</span> descreve o centro de massa desse sistema. Também, a média amostral e a esperança resumem a mesma característica. Enquanto que a primeira descreve a centralidade para uma variável em um banco de dados, uma variável aleatória já observada, a segunda descreve a centralidade para uma variável aleatória, isto é, descreve a incerteza sobre uma observação antes que esta ocorra. De forma técnica, a esperança de uma variável aleatória contínua é calculada da seguinte forma: <span class="math display">\[E[X] = \int_{-\infty}^{\infty}{x f_{X}(x)dx}\]</span></p></li>
<li><p><strong>Variância</strong> (populacional): A variância de uma variável aleatória, <span class="math inline">\(X\)</span>, é denotada por <span class="math inline">\(V[X]\)</span> e indica um resumo da variabilidade desta. Assim como a variância amostral descreve a variabilidade de uma variável em um banco de dados (já observado), a variância populacional descreve a variabilidade de uma variável aleatória (ainda não observada). De forma técnica, a variância de uma variável aleatória contínua é calculada da seguinte forma: <span class="math display">\[V[X] = \int_{-\infty}^{\infty}{(x-E[X])^2 f_{X}(x)}dx\]</span> Semelhantemente ao caso da variância amostral, a variância populacional não é medida na mesma escala da variável aleatória que ela representa. Para obter esta escala, é comum tomar a raiz quadrada da variância populacional. Esta medida é chamada de <strong>desvio padrão</strong> (populacional). Também é comum designarmos a variância de <span class="math inline">\(X\)</span> por <span class="math inline">\(\sigma^2_X\)</span>. Esta notação é conveniente pois permite designarmos o desvio padrão de <span class="math inline">\(X\)</span> por <span class="math inline">\(\sigma_X\)</span>.</p></li>
</ul>
<p>A seguir, estudaremos algumas funções de densidade essenciais para este curso.</p>
</div>
<div id="distribuicao-normal" class="section level1">
<h1>Distribuição normal</h1>
<p>Uma das distribuições mais usadas é a Normal. Formalmente, dizemos que <span class="math inline">\(X\)</span> tem distribuição normal com média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2\)</span> se <span class="math inline">\(X\)</span> pode assumir qualquer número real e sua densidade, <span class="math inline">\(f_{X}(x)\)</span>, tem a forma <span class="math display">\[
 f_{X}(x) = 
 \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
\]</span> Como diremos muitas vezes neste curso que “<span class="math inline">\(X\)</span> tem distribuição Normal com média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2\)</span>”, abreviaremos esta expressão por <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>. Se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, então obtem-se que <span class="math inline">\(E[X] = \mu\)</span> e <span class="math inline">\(Var[X] = \sigma^2\)</span>. A figura abaixo exibe a densidade da <span class="math inline">\(N(0,1)\)</span>, também conhecida por “normal padrão”.</p>
<pre class="r"><code>ggplot(data.frame(x = c(-3, 3)), aes(x)) + 
stat_function(fun = dnorm, colour=&quot;red&quot;, n = 100) </code></pre>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Note que a densidade tem um formato de sino com simetria ao redor do <span class="math inline">\(0\)</span>. Decorre que a normal padrão tem média <span class="math inline">\(0\)</span>. A densidade de uma normal com média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(1\)</span> terá o mesmo formato, só que transladado por <span class="math inline">\(\mu\)</span>. Este fato é ilustrado na figura a seguir, em que as curvas azul e verdem indicam, respectivamente, as densidades da <span class="math inline">\(N(-1,1)\)</span> e da <span class="math inline">\(N(1,1)\)</span>.</p>
<pre class="r"><code>ggplot(data.frame(x = c(-4,4)), aes(x)) + 
stat_function(fun = dnorm, colour = &quot;red&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, mean = -1), 
              colour = &quot;blue&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, mean = 1), 
              colour = &quot;green&quot;, n = 100) +
ylab(&quot;densidade&quot;)</code></pre>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Semelhantemente, a figura abaixo apresenta nas curvas verde, vermelha e azul, respectivamente, as distribuições <span class="math inline">\(N(0, 0.25)\)</span>, <span class="math inline">\(N(0, 1)\)</span> e <span class="math inline">\(N(0, 4)\)</span>. Note que a variância, <span class="math inline">\(\sigma^2\)</span>, altera a escala da densidade da normal. Quanto menor o valor de <span class="math inline">\(\sigma^2\)</span>, mais a densidade está concentrada ao redor da média.</p>
<pre class="r"><code>ggplot(data.frame(x = c(-6,6)), aes(x)) + 
stat_function(fun = dnorm, colour = &quot;red&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, sd = 2), 
              colour = &quot;blue&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, sd = 0.5), 
              colour = &quot;green&quot;, n = 100) +
ylab(&quot;densidade&quot;)</code></pre>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Uma relação útil é que aproximadamente 95% da densidade de uma <span class="math inline">\(N(\mu,\sigma^2)\)</span> está concentrada entre <span class="math inline">\(\mu-2\sigma\)</span> e <span class="math inline">\(\mu+2\sigma\)</span>. Na figura acima, temos que <span class="math inline">\(\mu=0\)</span>. Assim, aproximadamente 95% da área das curvas verde, vermelha e azul está concentrada, respectivamente, em <span class="math inline">\([-1,1]\)</span>, <span class="math inline">\([-2,2]\)</span> e <span class="math inline">\([-4,4]\)</span>. De forma mais formal, se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span> e <span class="math inline">\(\approx\)</span> significa aproximadamente, então <span class="math display">\[
P(\mu-2\sigma \leq X \leq \mu+2\sigma) 
\approx 0.95
\]</span></p>
<p>Se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, não é possível descrever <span class="math inline">\(P(X \leq x)\)</span> de forma analítica. Contudo, é possível obter uma aproximação analítica para esta quantidade no <strong>R</strong> usando a função <em>pnorm</em>. Por exemplo, o código abaixo calcula <span class="math inline">\(P(X \leq 4)\)</span> para uma <span class="math inline">\(N(2,9)\)</span>.</p>
<pre class="r"><code>pnorm(4, mean = 2, sd = 3)</code></pre>
<pre><code>## [1] 0.7475075</code></pre>
<p>Também a probabilidade de que uma <span class="math inline">\(N(2,9)\)</span> esteja entre <span class="math inline">\(1\)</span> e <span class="math inline">\(4\)</span> é obtida da seguinte forma:</p>
<pre class="r"><code>pnorm(4, mean = 2, sd = 3) - pnorm(1, mean = 2, sd = 3)</code></pre>
<pre><code>## [1] 0.3780661</code></pre>
<p>É possível transformar qualquer distribuição normal em uma normal padrão por meio de transformações lineares. Especificamente, se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, então <span class="math inline">\(\frac{X-\mu}{\sigma} \sim N(0,1)\)</span>. Por isso, podemos imaginar que obtemos uma <span class="math inline">\(N(\mu,\sigma^2)\)</span>, ao multiplicar uma normal padrão por <span class="math inline">\(\sigma\)</span> e somar <span class="math inline">\(\mu\)</span> ao resultado. O processo de calcular <span class="math inline">\(\frac{X-\mu}{\sigma}\)</span> é frequentemente chamado de padronização.</p>
<div id="teorema-central-do-limite" class="section level2">
<h2>Teorema Central do Limite</h2>
<p>O Teorema Central do Limite é um dos resultados mais importantes em Estatística e também uma das razões pelas quais a distribuição é tão importante neste curso. De forma suscinta, ele dita que, se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis aleatórias independentes que tem a mesma distribuição e tais que <span class="math inline">\(E[X_i] = \mu\)</span> e <span class="math inline">\(V[X_i] = \sigma^2\)</span>, então a média amostral é aproximadamente normal. Mais especificamente, <span class="math display">\[\bar{X} \approx N\left(\mu,\frac{\sigma^2}{n}\right)\]</span> Note que esta aproximação vale não importa qual seja a distribuição de cada observação. Assim, com pouquíssimas suposições é possível aproximar a distribuição da média amostral pela normal. Se padronizarmos a média amostral, obtemos a versão mais usual do Teorema do Limite Central: <span class="math display">\[\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \approx N(0,1)\]</span> A figura a seguir é um histograma de observações obtidas tomando a média de <span class="math inline">\(100\)</span> variáveis aleatórias uniformes entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>. Note que cada uniforme tem média <span class="math inline">\(0.5\)</span> e as médias amostrais estão dispersas em torno deste valor. Também, a distribuição uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span> tem variância <span class="math inline">\(\frac{1}{12}\)</span>. Assim, o Teorema Central do Limite dita que a média de 100 destas distribuições uniformes tem desvio padrão <span class="math inline">\(\sqrt{\frac{1}{12 \cdot 100}}\)</span>. Isto é, neste caso <span class="math inline">\(\bar{X} \approx N(0.5, 0.03)\)</span>. De fato, observamos na figura que a maior parte das observações estão dispersas a menos de dois desvios padrões, <span class="math inline">\(0.06\)</span>, da média populacional, <span class="math inline">\(0.5\)</span>.</p>
<pre class="r"><code>medias = rep(NA, 1000)
for(ii in 1:1000) 
{
  medias[ii] = mean(runif(100, 0, 1))
}
ggplot(aes(x = medias), data = data.frame(medias)) +
geom_histogram(aes(y = ..density..)) +
geom_density(colour=&quot;red&quot;)</code></pre>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="distribuicao-chi-quadrado" class="section level1">
<h1>Distribuição chi-quadrado</h1>
<ul>
<li><p>Se <span class="math inline">\(X\)</span> tem distribuição chi-quadrado com <span class="math inline">\(n\)</span> graus de liberdade, escrevemos <span class="math inline">\(X \sim \chi^2_n\)</span>. Neste caso, <span class="math display">\[f_{X}(x) = \frac{x^{0.5n-1}\exp(-0.5x)}{2^{0.5n}\Gamma(0.5n)},\]</span> <span class="math inline">\(E[X]=n\)</span> e <span class="math inline">\(V[X]=2n\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X \sim N(0,1)\)</span>, então <span class="math inline">\(X^2 \sim \chi^2_1\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis independentes e cada qual tem distribuição <span class="math inline">\(\chi^2_1\)</span>, então <span class="math inline">\(\sum_{i=1}^n X_i \sim \chi^2_n\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis independentes e tais que <span class="math inline">\(X_{i} \sim N(\mu, \sigma^2)\)</span>, então <span class="math inline">\(\frac{\sum_{i1=}^{n}(X_i-\bar{X})^2}{\sigma^2} \sim \chi^2_{n-1}\)</span>, ou seja, <span class="math inline">\(\frac{S^2}{\sigma^2} \sim \chi^2_{n-1}\)</span>.</p></li>
<li><p>No <strong>R</strong>, podemos obter a densidade e <span class="math inline">\(P(X \leq x)\)</span> para a chi-quadrado por meio dos comandos <em>dchisq</em> e <em>pchisq</em>.</p></li>
</ul>
</div>
<div id="distribuio-t-de-student" class="section level1">
<h1>Distribui??o T de Student</h1>
<ul>
<li><p>Designamos a distribui??o <span class="math inline">\(T\)</span> de Student com <span class="math inline">\(n\)</span> graus de liberdade por <span class="math inline">\(T_{n}\)</span>.</p></li>
<li><p>Se <span class="math inline">\(Z \sim N(0,1)\)</span> e <span class="math inline">\(S^2 \sim \chi^2_n\)</span> s?o vari?veis independentes, ent?o <span class="math inline">\(\frac{Z}{\sqrt{\frac{S^2}{n}}} \sim T_{n}\)</span>.</p></li>
<li><p>No <strong>R</strong>, podemos obter a densidade e <span class="math inline">\(P(X \leq x)\)</span> para a T de Student por meio dos comandos <em>dt</em> e <em>pt</em>.</p></li>
</ul>
</div>
<div id="distribuicao-f-de-snedcor" class="section level1">
<h1>Distribuição F de Snedcor</h1>
<ul>
<li><p>Se <span class="math inline">\(X\)</span> tem distribuição <span class="math inline">\(F\)</span> com parâmetros <span class="math inline">\(d_1\)</span> e <span class="math inline">\(d_2\)</span>, então escrevemos <span class="math inline">\(X \sim F_{d_1,d_2}\)</span>.</p></li>
<li><p><span class="math inline">\(X_1 \sim \chi^2_{d_1}\)</span>, <span class="math inline">\(X_2 \sim \chi^2_{d_2}\)</span> e <span class="math inline">\(X_1\)</span> e <span class="math inline">\(X_2\)</span> são independentes, então</p></li>
</ul>
<p><span class="math display">\[
\frac{\frac{X_1}{d_1}}{\frac{X_2}{d_2}}
\sim F_{d_1,d_2}
\]</span></p>
<ul>
<li>No <strong>R</strong>, podemos obter a densidade e <span class="math inline">\(P(X \leq x)\)</span> para a distribuição F por meio dos comandos <em>df</em> e <em>pf</em>.</li>
</ul>
</div>
<div id="exercicios" class="section level1">
<h1>Exercícios</h1>
<ol style="list-style-type: decimal">
<li><p>Se <span class="math inline">\(X\)</span> tem densidade entre uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span> e <span class="math inline">\(0 \leq x_1, x_2 \leq 1\)</span>, calcule <span class="math inline">\(P(x_1 \leq X \leq x_2)\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X\)</span> tem densidade uniforme entre <span class="math inline">\(1\)</span> e <span class="math inline">\(3\)</span>, qual é o valor da densidade de <span class="math inline">\(X\)</span> neste intervalo?</p></li>
<li><p>Calcule a esperança e a variância de uma variável aleatória com distribuição uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>.</p></li>
<li><p>Ache um intervalo tal que uma <span class="math inline">\(N(4,9)\)</span> e steja dentro deste com probabilidade aproximadamente <span class="math inline">\(95\%\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X \sim N(4,9)\)</span>, utilize o <strong>R</strong> para calcular <span class="math inline">\(P(-1 \leq X \leq 1)\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X \sim N(10, 100)\)</span>, indique uma transformação linear de <span class="math inline">\(X\)</span> que tem distribuição normal padrão.</p></li>
<li><p>Se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis independentes de mesma distribuição e tais que <span class="math inline">\(E[X_i] = 9\)</span> e <span class="math inline">\(V[X_i] = 16\)</span>, indique valores para <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> tal que <span class="math inline">\(P(a \leq \bar{X} \leq b) \approx 95\%\)</span>.</p></li>
<li><p>Um pesquisador utilizou uma mesma medida resumo em diversas variáveis de seu banco de dados. Para visualizar estas medidas, construiu um histograma delas. Este histograma se encontra abaixo. Com base no histograma, argumente se a medida resumo poderia ou não ser a média amostral.</p></li>
</ol>
<p><img src="/classes/2018_1_ipaee/post/aula_6_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="referencias" class="section level1">
<h1>Referências</h1>
</div>
