---
title: "Aulas 8 e 9 - Conceitos de testes de hipótese"
author: "Rafael Bassi Stern"
date: 2018-04-24
output: html_document
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>


<div id="testes-de-hipotese" class="section level1">
<h1>Testes de hipótese</h1>
<p>É comum que queiramos saber o quanto uma amostra corrobora uma hipótese científica. Neste caso, podemos aplicar um teste de hipótese, isto é, um procedimento que decidirá se a hipótese é ou não rejeitada diante da amostra obtida.</p>
<p>Por exemplo, considere que <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> são observações independentes realizadas com uma régua ao medir um determinado objeto. Suponha que <span class="math inline">\(X_{i} \sim N(\mu, \sigma_0^2)\)</span>, onde <span class="math inline">\(\sigma_0^2\)</span> é conhecido e indica precisão das medidas feitas com a régua. Uma pessoa poderia estar interessada na hipótese de que o objeto tem <span class="math inline">\(15\)</span> cm. Formalmente, chamamos esta hipótese de <strong>hipótese nula</strong> e a representamos por <span class="math inline">\(H_0: \mu = 15\)</span>. Gostaríamos de saber se é possível rejeitar <span class="math inline">\(H_0\)</span> com base nos dados.</p>
<div id="tipos-de-erro" class="section level2">
<h2>Tipos de erro</h2>
<p>Existem <span class="math inline">\(4\)</span> possíveis resultados que podem decorrer de um teste de hipótese. Note que o teste de hipótese pode rejeitar ou não rejeitar a hipótese nula e, também, esta hipótese pode ser verdadeira ou falsa. Assim, existem <span class="math inline">\(4\)</span> combinações de resultados possíveis:</p>
<ul>
<li>(Acerto) A hipótese nula é verdadeira e não é rejeitada.</li>
<li>(Acerto) A hipótese nula é falsa e é rejeitada.</li>
<li>(Erro tipo I) A hipótese nula é verdadeira e é rejeitada.</li>
<li>(Erro tipo II) A hipótese nula é falsa e não é rejeitada.</li>
</ul>
<p>Estas combinações podem ser representadas na seguinte tabela:</p>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["Rejeita H","Não rejeita H"],["Erro tipo I","Acerto"],["Acerto","Erro tipo II"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th><\/th>\n      <th>H é verdadeira<\/th>\n      <th>H é falsa<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"ti","order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Note que existe um balanço entre os erros tipo I e II. Por exemplo, se quiséssemos que a probabilidade de cometer um erro tipo I fosse 0, então poderíamos nunca rejeitar H. Contudo, neste caso, a probabilidade de cometer um erro tipo II seria 1. Analogamente, se sempre rejeitarmos H, então as probabilidades de erro tipo I e II serão, respectivamente, 1 e 0. Na prática, rejeitamos <span class="math inline">\(H_0\)</span> quando os dados oferecem evidência contrária a este hipótese. Assim, buscamos que as probabilidades de cometer um erro tipo I ou um erro tipo II sejam baixas.</p>
<p>Uma outra observação importante é que, em geral, não sabemos se cometemos um erro em um teste de hipótese. Para saber se <span class="math inline">\(H_0\)</span> é verdadeiro ou não, seria necessária observar a população. Como apenas somos capazes de observar a amostra, não somos capazes de determinar se <span class="math inline">\(H_0\)</span> é verdadeiro ou não. Assim, não sabemos se o resultado do teste de hipótese foi um acerto ou um erro.</p>
<p>Apesar da limitação acima, podemos controlar as probabilidades de erro tipo I e II de um teste. Isto é, podemos desenvolver testes que, antes de observar o banco de dados, tenham uma baixa probabilidade de cometer um erro.</p>
<p>Convecionou-se que a hipótese nula deve ser escolhida de tal forma que o erro tipo I seja mais grave que o erro tipo II. Por exemplo, é mais grave concluir que um rio não está poluído quando ele está poluído do que concluir que ele está poluído quando de fato não está. Assim, neste caso, tomaríamos a hipótese nula como aquela de que o rio está poluído, pois assim o erro tipo I seria o de rejeitar que o rio está poluído quando ele de fato está.</p>
<p>Como o erro tipo I é o mais grave, construímos testes de hipótese que diretamente controlam a probabilidade de erro tipo I. Formalmente, determinaremos testes de hipótese tais que o erro tipo I seja menor que um valor pré-determinado, <span class="math inline">\(\alpha\)</span>. É comum que <span class="math inline">\(\alpha\)</span> seja chamado de <strong>nível de significância</strong> do teste.</p>
<div id="exemplo-normal-com-variancia-conhecida" class="section level3">
<h3>Exemplo: normal com variância conhecida</h3>
<p>Considere que <span class="math inline">\(X_{1},\ldots,X_{n}\)</span> são observações independentes e tais que <span class="math inline">\(X_{i} \sim N(\mu,\sigma_0^2)\)</span>, onde <span class="math inline">\(\sigma_0^2\)</span> é conhecido. Por exemplo, <span class="math inline">\(X_i\)</span> pode ser o peso da <span class="math inline">\(i\)</span>-ésima vaca alimentada com uma determinada ração. Deseja-se provar que o peso médio de vacas alimentadas com esta ração é maior do que <span class="math inline">\(\mu_0 kg\)</span>, ou seja, a hipótese nula é <span class="math inline">\(H_0: \mu_0 \leq 500\)</span>.</p>
<p>Para capturar o quanta a evidência os dados trazem contra <span class="math inline">\(H_0\)</span>, podemos calcular o quanto a média amostral supera o valor de <span class="math inline">\(\mu_0\)</span>, isto é, <span class="math inline">\(\bar{X}-\mu_0\)</span>. Gostaríamos de rejeitar a hipótese nula quando <span class="math inline">\(\bar{X}\)</span> é muito maior que <span class="math inline">\(\mu_0\)</span>, isto é, <span class="math inline">\(\bar{X}-\mu_0 &gt; c\)</span>, onde <span class="math inline">\(c\)</span> é escolhido de forma a controlar o erro tipo I. A seguir, veremos como realizar este controle.</p>
<p>O erro tipo I é a probabilidade de rejeitar a hipótese nula quando ela é verdadeira. Isto é, para obter o erro tipo I, queremos calcular <span class="math inline">\(P(\bar{X} - \mu_0 &gt; c)\)</span> sob <span class="math inline">\(H_0\)</span>. Especificamente, gostaríamos que <span class="math inline">\(P(\bar{X} - \mu_0 &gt; c) \leq \alpha\)</span> sob <span class="math inline">\(H_0\)</span>. Para realizar esta desigualdade, note que decorre das propriedades da distribuição normal que, sob o valor extremo o extremo da hipótese nula (<span class="math inline">\(\mu = \mu_0\)</span>), temos que <span class="math inline">\(\bar{X}-\mu_0 \sim N\left(0,\frac{\sigma_0^2}{n}\right)\)</span>. Assim, utilizando a padronização da distribuição normal, obtemos que se <span class="math inline">\(\mu = 500\)</span>, <span class="math display">\[
 Z := \frac{\bar{X}-\mu_0}{\sqrt{\frac{\sigma_0^2}{n}}} \sim N(0, 1)
\]</span> Portanto, <span class="math display">\[
\begin{align*}
 P(\bar{X}-\mu_0 &gt; c)
 &amp;= P\left(\frac{\bar{X}-\mu_0}{\sqrt{\frac{\sigma_0^2}{n}}} &gt; \frac{\sqrt{n}c}{\sigma_0}\right) \\
 &amp;= P\left(Z &gt; \frac{\sqrt{n}c}{\sigma_0}\right) \\
 &amp;= 1 - P\left(Z \leq \frac{\sqrt{n}c}{\sigma_0}\right) \\
 &amp;= 1 - \text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right)
\end{align*}
\]</span> Para controlar o erro tipo <span class="math inline">\(I\)</span>, desejamos que sob <span class="math inline">\(H_0\)</span>, <span class="math inline">\(P(\bar{X}-\mu_0 &gt; c) = \alpha\)</span>. Utilizamos as equações acima, obtemos <span class="math display">\[
\begin{align*}
\alpha &amp;= 1 - \text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right) \\
1- \alpha &amp;= \text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right) \\
\text{qnorm}(1-\alpha) 
&amp;=  \text{qnorm}\left(\text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right)\right) \\
\text{qnorm}(1-\alpha) 
&amp;= \frac{\sqrt{n}c}{\sigma_0} \\
\frac{\text{qnorm}(1-\alpha)\sigma_0}{\sqrt{n}} &amp;= c
\end{align*}
\]</span> Assim, para controlar o erro tipo I em <span class="math inline">\(\alpha\)</span>, rejeitamos a a hipótese nula <span class="math inline">\(H_0:\mu \leq \mu_0\)</span> quando <span class="math display">\[\bar{X}-\mu_0 &gt; \frac{\text{qnorm}(1-\alpha)\sigma_0}{\sqrt{n}}.\]</span></p>
<p>Por exemplo, considere que observamos <span class="math inline">\(9\)</span> vacas alimentadas com a ração de interesse. Sabemos que o desvio padrão nos pesos destas vacas é de <span class="math inline">\(50 kg\)</span> e, portanto, o peso de cada vaca é <span class="math inline">\(X_i \sim N(\mu, 50)\)</span>. O peso média destas foi de <span class="math inline">\(530\)</span>. Se desejamos testar a hipótese <span class="math inline">\(H_0: \mu \leq 500\)</span> a um nível de <span class="math inline">\(\alpha = 5\%\)</span>, podemos realizar os cálculos no <strong>R</strong> da seguinte forma:</p>
<pre class="r"><code>mu0 = 500
n = 9
sigma0 = 50
media = 530
alpha = 0.05
qnorm(1-alpha)</code></pre>
<pre><code>## [1] 1.644854</code></pre>
<pre class="r"><code>c = qnorm(1-alpha) * sigma0 / sqrt(n)
c</code></pre>
<pre><code>## [1] 27.41423</code></pre>
<pre class="r"><code>media - mu0 &gt; c</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Como a média amostral supera <span class="math inline">\(c\)</span> a um nível de <span class="math inline">\(0.05\)</span>, rejeitamos a hipótese nula. Note que, se exercemos um maior controle sobre o erro tipo I, então não rejeitaremos a hipótese nula. Por exemplo, se tomássemos <span class="math inline">\(\alpha = 0.01\)</span>, então o teste de hipótese seria mais conservador e não rejeitaríamos a hipótese nula.</p>
<pre class="r"><code>alpha = 0.01
qnorm(1-alpha)</code></pre>
<pre><code>## [1] 2.326348</code></pre>
<pre class="r"><code>c = qnorm(1-alpha) * sigma0 / sqrt(n)
c</code></pre>
<pre><code>## [1] 38.77246</code></pre>
<pre class="r"><code>media - mu0  &gt; c</code></pre>
<pre><code>## [1] FALSE</code></pre>
</div>
</div>
<div id="p-valor" class="section level2">
<h2>p-valor</h2>
<p>Na amostra estudada no exemplo anterior, verificamos que se fixássemos <span class="math inline">\(\alpha = 0.05\)</span>, então o teste rejeitaria a hipótese nula. Por outro lado, se fixássemos <span class="math inline">\(\alpha = 0.01\)</span>, o teste não rejeitaria a hipótese nula. Isto ocorre pois quanto menor o valor de <span class="math inline">\(\alpha\)</span>, mais o teste fica conservador em rejeitar <span class="math inline">\(H_0\)</span>. Decorre deste comportamento que, enquanto que para valores “grandes” de <span class="math inline">\(\alpha\)</span>, o teste rejeitará <span class="math inline">\(H_0\)</span>, para valores “pequenos” de <span class="math inline">\(\alpha\)</span> o teste não rejeitará <span class="math inline">\(H_0\)</span>.</p>
<p>Um valor de interesse é o menor <span class="math inline">\(\alpha\)</span> tal que o teste rejeita <span class="math inline">\(H_0\)</span> para a amostra observada. Este <span class="math inline">\(\alpha^*\)</span> é comumente chamado de <strong>p-valor</strong>. Este valor pode ser muito útil para compartilhar resultados. Note que, para a amostra observada, se um pesquisador fixar um <span class="math inline">\(\alpha &gt; \alpha^*\)</span>, então ele rejeitará <span class="math inline">\(H_0\)</span>. Por outro lado, se ele fixar <span class="math inline">\(\alpha &lt; \alpha^*\)</span>, então não rejeitará <span class="math inline">\(H_0\)</span>. Assim, somente comparando o p-valor com o <span class="math inline">\(\alpha\)</span> fixado, é possível saber o resultado do teste. Portanto, mesmo pesquisadores fixando níveis de significância diferentes podem saber o resultado do teste de hipótese apenas observando o p-valor.</p>
<div id="p-valor-na-normal-com-variancia-conhecida" class="section level3">
<h3>p-valor na normal com variância conhecida</h3>
<p>No exemplo do teste de hipótese para a média da normal com variância conhecida, lembre que <span class="math inline">\(H_0: \mu \leq \mu_0\)</span> é rejeitado para todos os valores de <span class="math inline">\(\alpha\)</span> tais que:</p>
<p><span class="math display">\[\bar{X}-\mu_0 &gt; \frac{\text{qnorm}(1-\alpha)\sigma_0}{\sqrt{n}}\]</span> Portanto, o menor valor de <span class="math inline">\(\alpha\)</span> tal que <span class="math inline">\(H_0\)</span> é rejeitado, <span class="math inline">\(\alpha^*\)</span> é tal que <span class="math display">\[\bar{X}-\mu_0 = \frac{\text{qnorm}(1-\alpha^*)\sigma_0}{\sqrt{n}}\]</span> Com algumas manipulações aritméticas podemos determinar o valor de <span class="math inline">\(\alpha^*\)</span>, isto é, o p-valor: <span class="math display">\[
\begin{align*}
 \bar{X}-\mu_0 
 &amp;= \frac{\text{qnorm}(1-\alpha^*)\sigma_0}{\sqrt{n}} \\
 \frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0} 
 &amp;= \text{qnorm}(1-\alpha^*) \\
 \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
 &amp;= \text{pnorm}(\text{qnorm}(1-\alpha^*)) \\
 \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
 &amp;= 1 - \alpha^* \\
 1 - \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
 &amp;= \alpha^*
\end{align*}
\]</span> Portanto, o p-valor neste caso é o <span class="math inline">\(\alpha^*\)</span> tal que <span class="math display">\[
\alpha^* = 1 - \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
\]</span></p>
</div>
</div>
</div>
<div id="exercicios" class="section level1">
<h1>Exercícios</h1>
<ol style="list-style-type: decimal">
<li><p>Descreva em suas próprias palavras: teste de hipótese, erro tipo I, erro tipo II, nível de significância e p-valor.</p></li>
<li><p>Um cientista mede um objeto <span class="math inline">\(9\)</span> vezes com um paquímetro e observa os valores em mm de: 1.2, 1.4, 1.7, 1.3, 1.5, 1.1, 1.8, 1.4, 1.1. Se as medições com o paquímetro tem desvio padrão de 0.2 mm, o pesquisador consegue rejeitar a hipótese de que o comprimento do objeto é menor do que <span class="math inline">\(1.3 mm\)</span>? Qual o p-valor para esta hipótese na amostra observada?</p></li>
<li><p>Considere o caso da normal com variância conhecida. Ou seja, cada observação é tal que <span class="math inline">\(X_{i} \sim N(\mu,\sigma_0^2)\)</span>. Considere que desejamos testar <span class="math inline">\(H_0: \mu \geq \mu_0\)</span>. Neste caso, faria sentido calcular como evidência contra <span class="math inline">\(H_0\)</span> o quanto <span class="math inline">\(\bar{X}\)</span> é menor que <span class="math inline">\(\mu_0\)</span>? Se sim, rejeitaríamos <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(\bar{X}-\mu_0 &lt; c\)</span>. Utilizando passos análogos ao da seção da normal com variância conhecida, o valor de <span class="math inline">\(c\)</span> tal que a probabilidade de erro tipo I é controlada por <span class="math inline">\(\alpha\)</span>. Determine o p-valor deste teste.</p></li>
<li><p>Considere novamente o caso da normal com variância conhecida, ou seja, cada observação é tal que <span class="math inline">\(X_{i} \sim N(\mu,\sigma_0^2)\)</span>. A medida <span class="math inline">\(|\bar{X}-\mu_0|\)</span> captura evidência contra <span class="math inline">\(H_0: \mu = \mu_0\)</span>? Se desejamos rejeitar <span class="math inline">\(H_0\)</span> quando <span class="math inline">\(|\bar{X}-\mu_0| &gt; c\)</span>, determine o valor de <span class="math inline">\(c\)</span> que controla o erro tipo I em <span class="math inline">\(\alpha\)</span>. Determine o p-valor deste teste.</p></li>
</ol>
</div>
